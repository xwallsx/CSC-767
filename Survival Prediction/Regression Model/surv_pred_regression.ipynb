{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "surv-pred-regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shalabh147/Brain-Tumor-Segmentation-and-Survival-Prediction-using-Deep-Neural-Networks/blob/master/surv_pred_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "ghhRoTgL1I2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "# import keras\n",
        "# from ensorflow import keras\n",
        "from keras import layers\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout,Maximum,Flatten\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose,Conv3D,Conv3DTranspose,UpSampling2D\n",
        "# from tensorflow.keras.layers.convolutional import Conv2D, Conv2DTranspose,Conv3D,Conv3DTranspose,UpSampling2D\n",
        "# from tensorflow.keras.layers.convolutional import Conv2D, Conv2DTranspose,Conv3D,Conv3DTranspose,UpSampling2D\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D,MaxPooling3D,AveragePooling2D\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from sklearn.utils import class_weight\n",
        "from keras.models import Sequential\n",
        "import nibabel as nib\n",
        "\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "path1 = '../input/vs-brats2018/miccai_brats_2018_data_training/survival_data.csv'\n",
        "#print(os.listdir(path))\n",
        "# Brats18_CBICA_ANP_1\n",
        "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "lAyichNT1I2a",
        "colab_type": "code",
        "colab": {},
        "outputId": "ea77406a-13b0-4b0b-e7f3-bf7bbf7edd43"
      },
      "source": [
        "import csv\n",
        "#import pickle\n",
        "\n",
        "#from joblib import dump\n",
        "\n",
        "age_dict = {}\n",
        "days_dict = {}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open(path1, mode='r') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file,delimiter = ',')\n",
        "    line_count = 0\n",
        "    a = 0\n",
        "    b = 0\n",
        "    c = 0\n",
        "    max_days = 0\n",
        "    for row in csv_reader:\n",
        "        if line_count == 0:\n",
        "            print(f'Column names are {\", \".join(row)}')\n",
        "            line_count += 1\n",
        "        else:\n",
        "            print(row)\n",
        "            key = row[0]\n",
        "            age = row[1]\n",
        "            days = row[2]\n",
        "            age_dict[key] = float(age)\n",
        "            days_dict[key] = int(days)\n",
        "            max_days = max(max_days,int(days))\n",
        "            if int(days) < 250:\n",
        "                a += 1\n",
        "            elif (int(days) >= 250 and int(days) <= 500):\n",
        "                b += 1\n",
        "            else:\n",
        "                c += 1\n",
        "            line_count+=1\n",
        "\n",
        "    print(f'Processed {line_count} lines.')\n",
        "    #age_m = np.zeros((1,1))\n",
        "    print(a,b,c)\n",
        "    print(max_days)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column names are BraTS18ID, Age, Survival, ResectionStatus\n",
            "['Brats18_TCIA08_167_1', '74.907', '153', 'NA']\n",
            "['Brats18_TCIA08_242_1', '66.479', '147', 'NA']\n",
            "['Brats18_TCIA08_319_1', '64.86', '254', 'NA']\n",
            "['Brats18_TCIA08_469_1', '63.899', '519', 'NA']\n",
            "['Brats18_TCIA08_218_1', '57.345', '346', 'NA']\n",
            "['Brats18_TCIA08_406_1', '78.745', '82', 'NA']\n",
            "['Brats18_TCIA08_280_1', '57.362', '508', 'NA']\n",
            "['Brats18_TCIA08_105_1', '66.627', '77', 'NA']\n",
            "['Brats18_TCIA08_278_1', '50.501', '1458', 'NA']\n",
            "['Brats18_TCIA06_247_1', '76.699', '244', 'NA']\n",
            "['Brats18_TCIA06_372_1', '74.521', '213', 'NA']\n",
            "['Brats18_TCIA06_165_1', '51.756', '5', 'NA']\n",
            "['Brats18_TCIA06_409_1', '69.266', '99', 'NA']\n",
            "['Brats18_TCIA06_184_1', '61.167', '434', 'NA']\n",
            "['Brats18_TCIA05_277_1', '70.367', '232', 'NA']\n",
            "['Brats18_TCIA05_478_1', '59.255', '30', 'NA']\n",
            "['Brats18_TCIA04_437_1', '46.953', '333', 'NA']\n",
            "['Brats18_TCIA04_361_1', '75.973', '476', 'NA']\n",
            "['Brats18_TCIA04_192_1', '75.962', '121', 'NA']\n",
            "['Brats18_TCIA04_479_1', '56.4', '372', 'NA']\n",
            "['Brats18_TCIA04_111_1', '75.263', '626', 'NA']\n",
            "['Brats18_TCIA04_343_1', '52.679', '296', 'NA']\n",
            "['Brats18_TCIA04_149_1', '36.852', '448', 'NA']\n",
            "['Brats18_TCIA03_474_1', '61.408', '635', 'NA']\n",
            "['Brats18_TCIA03_419_1', '70.592', '327', 'NA']\n",
            "['Brats18_TCIA03_199_1', '48.825', '1282', 'NA']\n",
            "['Brats18_TCIA03_133_1', '63.762', '382', 'NA']\n",
            "['Brats18_TCIA03_296_1', '60.427', '22', 'NA']\n",
            "['Brats18_TCIA03_257_1', '69.326', '425', 'NA']\n",
            "['Brats18_TCIA03_498_1', '59.282', '467', 'NA']\n",
            "['Brats18_TCIA03_138_1', '71.874', '82', 'NA']\n",
            "['Brats18_TCIA03_338_1', '76.425', '468', 'NA']\n",
            "['Brats18_TCIA03_265_1', '59.584', '103', 'NA']\n",
            "['Brats18_TCIA03_375_1', '60', '946', 'NA']\n",
            "['Brats18_TCIA03_121_1', '30.408', '747', 'NA']\n",
            "['Brats18_TCIA02_274_1', '54.967', '357', 'NA']\n",
            "['Brats18_TCIA02_473_1', '61.022', '175', 'NA']\n",
            "['Brats18_TCIA02_322_1', '57.362', '621', 'NA']\n",
            "['Brats18_TCIA02_179_1', '46.677', '405', 'NA']\n",
            "['Brats18_TCIA02_368_1', '62.562', '317', 'NA']\n",
            "['Brats18_TCIA02_135_1', '69.364', '828', 'NA']\n",
            "['Brats18_TCIA02_471_1', '76.614', '111', 'NA']\n",
            "['Brats18_TCIA02_394_1', '64.247', '616', 'NA']\n",
            "['Brats18_TCIA02_300_1', '64.378', '127', 'NA']\n",
            "['Brats18_TCIA02_151_1', '47.973', '1731', 'NA']\n",
            "['Brats18_TCIA02_118_1', '47.321', '104', 'NA']\n",
            "['Brats18_TCIA02_226_1', '73.578', '329', 'NA']\n",
            "['Brats18_TCIA02_455_1', '54.844', '424', 'NA']\n",
            "['Brats18_TCIA02_283_1', '74.836', '262', 'NA']\n",
            "['Brats18_TCIA02_430_1', '53.866', '71', 'NA']\n",
            "['Brats18_TCIA02_321_1', '81.211', '67', 'NA']\n",
            "['Brats18_TCIA02_314_1', '40.353', '362', 'NA']\n",
            "['Brats18_TCIA02_290_1', '43.112', '737', 'NA']\n",
            "['Brats18_TCIA02_377_1', '63.762', '812', 'NA']\n",
            "['Brats18_TCIA02_198_1', '54.279', '394', 'NA']\n",
            "['Brats18_TCIA02_331_1', '84.844', '187', 'NA']\n",
            "['Brats18_TCIA02_491_1', '81.112', '82', 'NA']\n",
            "['Brats18_TCIA01_150_1', '51.115', '1489', 'NA']\n",
            "['Brats18_TCIA01_335_1', '54.474', '355', 'NA']\n",
            "['Brats18_TCIA01_411_1', '42.904', '822', 'NA']\n",
            "['Brats18_TCIA01_203_1', '45.926', '268', 'NA']\n",
            "['Brats18_TCIA01_231_1', '63.805', '1561', 'NA']\n",
            "['Brats18_TCIA01_390_1', '63.575', '634', 'NA']\n",
            "['Brats18_TCIA01_235_1', '57.973', '804', 'NA']\n",
            "['Brats18_TCIA01_499_1', '50.082', '600', 'NA']\n",
            "['Brats18_TCIA01_412_1', '68.759', '291', 'NA']\n",
            "['Brats18_TCIA01_448_1', '44.449', '199', 'NA']\n",
            "['Brats18_TCIA01_401_1', '78.792', '448', 'NA']\n",
            "['Brats18_TCIA01_147_1', '61.416', '209', 'NA']\n",
            "['Brats18_TCIA01_378_1', '74.145', '110', 'NA']\n",
            "['Brats18_TCIA01_201_1', '60.729', '430', 'NA']\n",
            "['Brats18_TCIA01_429_1', '54.986', '86', 'NA']\n",
            "['Brats18_TCIA01_186_1', '33.888', '370', 'NA']\n",
            "['Brats18_TCIA01_460_1', '18.975', '630', 'NA']\n",
            "['Brats18_TCIA01_190_1', '61.526', '322', 'NA']\n",
            "['Brats18_TCIA01_425_1', '56.208', '558', 'NA']\n",
            "['Brats18_2013_11_1', '29.12', '150', 'GTR']\n",
            "['Brats18_2013_27_1', '68.02', '120', 'GTR']\n",
            "['Brats18_CBICA_BHM_1', '62.03', '436', 'STR']\n",
            "['Brats18_CBICA_BHB_1', '55.595', '510', 'GTR']\n",
            "['Brats18_CBICA_AZH_1', '54.915', '401', 'GTR']\n",
            "['Brats18_CBICA_AZD_1', '46.258', '448', 'GTR']\n",
            "['Brats18_CBICA_AYW_1', '49.874', '734', 'NA']\n",
            "['Brats18_CBICA_AYU_1', '63.781', '58', 'GTR']\n",
            "['Brats18_CBICA_AYI_1', '65.921', '387', 'GTR']\n",
            "['Brats18_CBICA_AYA_1', '74.836', '50', 'GTR']\n",
            "['Brats18_CBICA_AXW_1', '79.211', '191', 'GTR']\n",
            "['Brats18_CBICA_AXQ_1', '66.282', '114', 'GTR']\n",
            "['Brats18_CBICA_AXO_1', '56.301', '394', 'NA']\n",
            "['Brats18_CBICA_AXN_1', '85.762', '345', 'GTR']\n",
            "['Brats18_CBICA_AXM_1', '66.934', '438', 'STR']\n",
            "['Brats18_CBICA_AXL_1', '74.63', '168', 'GTR']\n",
            "['Brats18_CBICA_AXJ_1', '27.811', '1767', 'GTR']\n",
            "['Brats18_CBICA_AWI_1', '46.551', '375', 'GTR']\n",
            "['Brats18_CBICA_AWH_1', '52.764', '139', 'GTR']\n",
            "['Brats18_CBICA_AWG_1', '55.532', '180', 'GTR']\n",
            "['Brats18_CBICA_AVV_1', '72.293', '387', 'GTR']\n",
            "['Brats18_CBICA_AVJ_1', '45.244', '614', 'GTR']\n",
            "['Brats18_CBICA_AVG_1', '63.359', '579', 'GTR']\n",
            "['Brats18_CBICA_AUR_1', '70.252', '12', 'GTR']\n",
            "['Brats18_CBICA_AUQ_1', '60.816', '1337', 'NA']\n",
            "['Brats18_CBICA_AUN_1', '68.504', '376', 'GTR']\n",
            "['Brats18_CBICA_ATX_1', '36.784', '1592', 'GTR']\n",
            "['Brats18_CBICA_ATV_1', '62.159', '453', 'GTR']\n",
            "['Brats18_CBICA_ATP_1', '51.589', '385', 'GTR']\n",
            "['Brats18_CBICA_ATF_1', '68.726', '152', 'GTR']\n",
            "['Brats18_CBICA_ATD_1', '69.178', '355', 'GTR']\n",
            "['Brats18_CBICA_ATB_1', '71.126', '208', 'GTR']\n",
            "['Brats18_CBICA_ASY_1', '66.51', '610', 'STR']\n",
            "['Brats18_CBICA_ASW_1', '68.359', '239', 'GTR']\n",
            "['Brats18_CBICA_ASV_1', '54.751', '597', 'GTR']\n",
            "['Brats18_CBICA_ASU_1', '81.285', '85', 'STR']\n",
            "['Brats18_CBICA_ASO_1', '52.348', '265', 'STR']\n",
            "['Brats18_CBICA_ASN_1', '39.488', '407', 'STR']\n",
            "['Brats18_CBICA_ASK_1', '77.337', '522', 'GTR']\n",
            "['Brats18_CBICA_ASH_1', '46.57', '660', 'GTR']\n",
            "['Brats18_CBICA_ASG_1', '57.71', '208', 'STR']\n",
            "['Brats18_CBICA_ASE_1', '46.814', '318', 'STR']\n",
            "['Brats18_CBICA_ASA_1', '63.764', '210', 'STR']\n",
            "['Brats18_CBICA_ARZ_1', '54.825', '871', 'STR']\n",
            "['Brats18_CBICA_ARW_1', '44.416', '495', 'STR']\n",
            "['Brats18_CBICA_ARF_1', '75.312', '726', 'GTR']\n",
            "['Brats18_CBICA_AQZ_1', '63.345', '286', 'STR']\n",
            "['Brats18_CBICA_AQY_1', '57.718', '229', 'STR']\n",
            "['Brats18_CBICA_AQV_1', '53.362', '84', 'GTR']\n",
            "['Brats18_CBICA_AQU_1', '72.879', '30', 'STR']\n",
            "['Brats18_CBICA_AQT_1', '75.978', '172', 'GTR']\n",
            "['Brats18_CBICA_AQR_1', '71.37', '89', 'GTR']\n",
            "['Brats18_CBICA_AQQ_1', '69.992', '33', 'STR']\n",
            "['Brats18_CBICA_AQP_1', '46.452', '1283', 'GTR']\n",
            "['Brats18_CBICA_AQO_1', '67.86', '473', 'GTR']\n",
            "['Brats18_CBICA_AQN_1', '63.192', '488', 'STR']\n",
            "['Brats18_CBICA_AQJ_1', '66.074', '170', 'STR']\n",
            "['Brats18_CBICA_AQG_1', '53.605', '466', 'STR']\n",
            "['Brats18_CBICA_AQD_1', '73.036', '32', 'STR']\n",
            "['Brats18_CBICA_AQA_1', '76.367', '106', 'GTR']\n",
            "['Brats18_CBICA_APZ_1', '60.063', '336', 'STR']\n",
            "['Brats18_CBICA_APY_1', '45.548', '203', 'STR']\n",
            "['Brats18_CBICA_APR_1', '62.704', '23', 'STR']\n",
            "['Brats18_CBICA_AOZ_1', '46.666', '331', 'GTR']\n",
            "['Brats18_CBICA_AOP_1', '67.833', '332', 'GTR']\n",
            "['Brats18_CBICA_AOO_1', '44.162', '350', 'GTR']\n",
            "['Brats18_CBICA_AOH_1', '56.921', '576', 'GTR']\n",
            "['Brats18_CBICA_AOD_1', '60.581', '55', 'NA']\n",
            "['Brats18_CBICA_ANZ_1', '68.049', '287', 'GTR']\n",
            "['Brats18_CBICA_ANP_1', '61.605', '486', 'GTR']\n",
            "['Brats18_CBICA_ANI_1', '58.258', '439', 'GTR']\n",
            "['Brats18_CBICA_ANG_1', '55.759', '368', 'GTR']\n",
            "['Brats18_CBICA_AMH_1', '62.614', '169', 'GTR']\n",
            "['Brats18_CBICA_AME_1', '51.734', '359', 'GTR']\n",
            "['Brats18_CBICA_ALX_1', '59.693', '698', 'GTR']\n",
            "['Brats18_CBICA_ALU_1', '65.899', '495', 'GTR']\n",
            "['Brats18_CBICA_ALN_1', '60.942', '421', 'STR']\n",
            "['Brats18_CBICA_ABY_1', '48.367', '515', 'GTR']\n",
            "['Brats18_CBICA_ABO_1', '56.419', '1155', 'GTR']\n",
            "['Brats18_CBICA_ABN_1', '68.285', '1278', 'STR']\n",
            "['Brats18_CBICA_ABM_1', '69.912', '503', 'GTR']\n",
            "['Brats18_CBICA_ABE_1', '67.126', '269', 'GTR']\n",
            "['Brats18_CBICA_ABB_1', '68.493', '465', 'GTR']\n",
            "['Brats18_CBICA_AAP_1', '39.068', '788', 'GTR']\n",
            "['Brats18_CBICA_AAL_1', '54.301', '464', 'GTR']\n",
            "['Brats18_CBICA_AAG_1', '52.263', '616', 'GTR']\n",
            "['Brats18_CBICA_AAB_1', '60.463', '289', 'GTR']\n",
            "Processed 164 lines.\n",
            "55 64 44\n",
            "1767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DfXkPloH1I2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SurvPredNet(input_img,age_m):\n",
        "    #input_img = BatchNormalization()(input_img)\n",
        "    a1 = Conv2D(16,kernel_size = (3,3) , padding='same')(input_img)\n",
        "    a1 = BatchNormalization()(a1)\n",
        "    a1 = Activation('relu')(a1)\n",
        "    \n",
        "    a1 = MaxPooling2D(pool_size = (2,2) , strides = (2,2))(a1)\n",
        "    \n",
        "    a1 = Conv2D(24,kernel_size = (3,3) , padding='same')(a1)\n",
        "    a1 = BatchNormalization()(a1)\n",
        "    a1 = Activation('relu')(a1)\n",
        "    \n",
        "    a1 = MaxPooling2D(pool_size = (2,2) , strides = (2,2))(a1)\n",
        "    \n",
        "    a1 = Conv2D(32,kernel_size = (3,3) , padding='same')(a1)\n",
        "    a1 = BatchNormalization()(a1)\n",
        "    a1 = Activation('relu')(a1)\n",
        "    \n",
        "    a1 = MaxPooling2D(pool_size = (2,2) , strides = (2,2))(a1)\n",
        "    \n",
        "    a1 = Conv2D(32,kernel_size = (3,3) , padding='same')(a1)\n",
        "    a1 = BatchNormalization()(a1)\n",
        "    a1 = Activation('relu')(a1)\n",
        "    \n",
        "    a1 = MaxPooling2D(pool_size = (2,2) , strides = (2,2))(a1)\n",
        "    \n",
        "    a1 = Conv2D(32,kernel_size = (3,3) , padding='same')(a1)\n",
        "    a1 = BatchNormalization()(a1)\n",
        "    a1 = Activation('relu')(a1)\n",
        "    \n",
        "    a1 = AveragePooling2D(pool_size = (6,6) , strides = (1,1))(a1)\n",
        "    \n",
        "    a1 = Conv2D(32,kernel_size = (3,3) , padding = 'same')(a1)\n",
        "    a1 = BatchNormalization()(a1)\n",
        "    a1 = Activation('relu')(a1)\n",
        "    \n",
        "    a1 = AveragePooling2D(pool_size = (5,5) , strides = (1,1))(a1)\n",
        "    a1 = Conv2D(32,kernel_size = (3,3) , padding = 'same')(a1)\n",
        "    a1 = BatchNormalization()(a1)\n",
        "    a1 = Activation('relu')(a1)\n",
        "    \n",
        "    a1 = AveragePooling2D(pool_size = (6,6) , strides = (1,1))(a1)\n",
        "    \n",
        "    a1 = Flatten()(a1)\n",
        "    a1 = concatenate([a1,age_m])\n",
        "    a1 = BatchNormalization()(a1)\n",
        "    \n",
        "    a1 = Dense(32,activation = 'relu')(a1)\n",
        "    a1 = Dense(16,activation = 'relu')(a1)\n",
        "    outputs = Dense(1,activation = 'sigmoid')(a1)\n",
        "    \n",
        "    model = Model(inputs = [input_img,age_m] , outputs = outputs)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mN5yEJpP1I2x",
        "colab_type": "code",
        "colab": {},
        "outputId": "6b4d3378-fcd5-46df-e52f-c7ebe85c049b"
      },
      "source": [
        "input_img = Input((240,240,5))\n",
        "age_m = Input((1))\n",
        "model = SurvPredNet(input_img,age_m)\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 240, 240, 5) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 240, 240, 16) 736         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 240, 240, 16) 64          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 240, 240, 16) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 120, 120, 16) 0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 120, 120, 24) 3480        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 120, 120, 24) 96          conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 120, 120, 24) 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 60, 60, 24)   0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 60, 60, 32)   6944        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 60, 60, 32)   128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 60, 60, 32)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 30, 30, 32)   0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 30, 30, 32)   9248        max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 30, 30, 32)   128         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 30, 30, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 15, 15, 32)   0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 15, 15, 32)   9248        max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 15, 15, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 15, 15, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 10, 10, 32)   0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 10, 10, 32)   9248        average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 10, 10, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 10, 10, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 6, 6, 32)     0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 6, 6, 32)     9248        average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 6, 6, 32)     128         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 6, 6, 32)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 1, 1, 32)     0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 32)           0           average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 33)           0           flatten_1[0][0]                  \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 33)           132         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 32)           1088        batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 16)           528         dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            17          dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 50,717\n",
            "Trainable params: 50,251\n",
            "Non-trainable params: 466\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_-vYbDAG1I23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '../input/vs-brats2018/miccai_brats_2018_data_training/HGG'\n",
        "all_images = os.listdir(path)\n",
        "#print(len(all_images))\n",
        "all_images.sort()\n",
        "\n",
        "def standardize(image):\n",
        "\n",
        "  standardized_image = np.zeros(image.shape)\n",
        "\n",
        "  #\n",
        " \n",
        "      # iterate over the `z` dimension\n",
        "  for z in range(image.shape[2]):\n",
        "      # get a slice of the image\n",
        "      # at channel c and z-th dimension `z`\n",
        "      image_slice = image[:,:,z]\n",
        "\n",
        "      # subtract the mean from image_slice\n",
        "      centered = image_slice - np.mean(image_slice)\n",
        "     \n",
        "      # divide by the standard deviation (only if it is different from zero)\n",
        "      if(np.std(centered)!=0):\n",
        "          centered = centered/np.std(centered)\n",
        "\n",
        "      # update  the slice of standardized image\n",
        "      # with the scaled centered and scaled image\n",
        "      standardized_image[:, :, z] = centered\n",
        "\n",
        "  ### END CODE HERE ###\n",
        "\n",
        "  return standardized_image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1AqWZ3Mf1I28",
        "colab_type": "code",
        "colab": {},
        "outputId": "5abf322a-f48c-4c9c-b20f-47d4e1672085"
      },
      "source": [
        "loss_hist = []\n",
        "accu_hist = []\n",
        "epoch_wise_loss = []\n",
        "epoch_wise_accu = []\n",
        "#for epochs in range(45):\n",
        "epoch_loss = 0\n",
        "epoch_accu = 0\n",
        "input_to_model = np.zeros((134,240,240,5))\n",
        "age = np.zeros((134,1))\n",
        "ground_truth = np.zeros((134,1))\n",
        "cnt = 0\n",
        "for image_num in range(170):\n",
        "    #print(epochs)\n",
        "    #print(\"image_num \",image_num)\n",
        "    #print(\"cnt\" ,cnt)\n",
        "    data = np.zeros((240,240,155,4))\n",
        "    image_data2=np.zeros((240,240,155))\n",
        "\n",
        "    # data preprocessing starts here\n",
        "\n",
        "    x = all_images[image_num]\n",
        "    \n",
        "    if x in days_dict:\n",
        "        #print(cnt)\n",
        "        #print(x)\n",
        "        folder_path = path + '/' + x;\n",
        "        modalities = os.listdir(folder_path)\n",
        "        modalities.sort()\n",
        "        #data = []\n",
        "        w = 0\n",
        "        for j in range(len(modalities)):\n",
        "          #print(modalities[j])\n",
        "\n",
        "          image_path = folder_path + '/' + modalities[j]\n",
        "          if not(image_path.find('seg.nii') == -1):\n",
        "            img = nib.load(image_path);\n",
        "            image_data2 = img.get_data()\n",
        "            image_data2 = np.asarray(image_data2)\n",
        "            #print(\"Entered ground truth\")\n",
        "          else:\n",
        "            img = nib.load(image_path);\n",
        "            image_data = img.get_data()\n",
        "            image_data = np.asarray(image_data)\n",
        "            image_data = standardize(image_data)\n",
        "            data[:,:,:,w] = image_data\n",
        "            #print(\"Entered modality\")\n",
        "            w = w+1\n",
        "\n",
        "        #print(data.shape)\n",
        "        #print(image_data2.shape)\n",
        "        image_data2[image_data2 == 4] = 3\n",
        "\n",
        "        input_to_model[cnt,:,:,:4] = data[:,:,75,:]\n",
        "        input_to_model[cnt,:,:,4] = image_data2[:,:,75]\n",
        "        #age = np.zeros((1,1))\n",
        "        age[cnt,0] = float(age_dict[x])\n",
        "        days = int(days_dict[x])\n",
        "        \n",
        "\n",
        "        #ground_truth = np.zeros((1,3))\n",
        "        #print(age[cnt,0])\n",
        "        '''\n",
        "        if int(days) < 300:\n",
        "            ground_truth[cnt,0] = 1\n",
        "        elif (int(days) >= 300 and int(days) <= 450):\n",
        "            ground_truth[cnt,1] = 1\n",
        "        else:\n",
        "            ground_truth[cnt,2] = 1 \n",
        "        '''\n",
        "        ground_truth[cnt,0] = int(days)/max_days\n",
        "        #print(ground_truth[cnt])\n",
        "        cnt += 1\n",
        "        \n",
        "\n",
        "    #y_to = keras.utils.to_categorical(y_to,num_classes=4)\n",
        "history = model.fit(x=[input_to_model,age],y=ground_truth, epochs = 90 , batch_size = 64)\n",
        "print(history.history['loss'])\n",
        "#epoch_loss += history.history['loss'][0]\n",
        "#epoch_accu += history.history['accuracy'][0]\n",
        "\n",
        "#loss_hist.append(history.history['loss'])\n",
        "#accu_hist.append(history.history['accuracy'])\n",
        "\n",
        "model.save('../working/surv_pred5.h5')\n",
        "#epoch_loss = epoch_loss/180\n",
        "#epoch_accu = epoch_accu/180\n",
        "\n",
        "#epoch_wise_loss.append(epoch_loss)\n",
        "#epoch_wise_accu.append(epoch_accu)\n",
        " \n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model_loss vs epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epochs')\n",
        "s = '../working/epochwise_loss'\n",
        "plt.savefig(s)\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "#plt.plot(history.history['mse'])\n",
        "#plt.title('Model_Accuracy vs epochs')\n",
        "#plt.ylabel('Accuracy')\n",
        "#plt.xlabel('epochs')\n",
        "#s = '../working/epochwise_accuracy'\n",
        "#plt.savefig(s)\n",
        "#plt.show()\n",
        "#plt.close()\n",
        "\n",
        "'''\n",
        "plt.plot(accu_hist)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "s = '../working/accuracy_plot_' + str(epochs)\n",
        "plt.savefig(s)\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "plt.plot(loss_hist)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "s = '../working/loss_plot_' + str(epochs)\n",
        "plt.savefig(s)\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "model.save('../working/2d_4class_axis1.h5')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:42: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
            "\n",
            "* deprecated from version: 3.0\n",
            "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
            "\n",
            "* deprecated from version: 3.0\n",
            "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.1564 - mse: 0.1564\n",
            "Epoch 2/90\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0888 - mse: 0.0888\n",
            "Epoch 3/90\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0638 - mse: 0.0638\n",
            "Epoch 4/90\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0529 - mse: 0.0529\n",
            "Epoch 5/90\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0498 - mse: 0.0498\n",
            "Epoch 6/90\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0447 - mse: 0.0447\n",
            "Epoch 7/90\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0373 - mse: 0.0373\n",
            "Epoch 8/90\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0346 - mse: 0.0346\n",
            "Epoch 9/90\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0324 - mse: 0.0324\n",
            "Epoch 10/90\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0304 - mse: 0.0304\n",
            "Epoch 11/90\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0280 - mse: 0.0280\n",
            "Epoch 12/90\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0287 - mse: 0.0287\n",
            "Epoch 13/90\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0281 - mse: 0.0281\n",
            "Epoch 14/90\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0261 - mse: 0.0261\n",
            "Epoch 15/90\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0234 - mse: 0.0234\n",
            "Epoch 16/90\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0237 - mse: 0.0237\n",
            "Epoch 17/90\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0248 - mse: 0.0248\n",
            "Epoch 18/90\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0249 - mse: 0.0249\n",
            "Epoch 19/90\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0212 - mse: 0.0212: 0s - loss: 0.0217 - mse: 0.021\n",
            "Epoch 20/90\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0248 - mse: 0.0248\n",
            "Epoch 21/90\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0221 - mse: 0.0221\n",
            "Epoch 22/90\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0221 - mse: 0.0221\n",
            "Epoch 23/90\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0206 - mse: 0.0206\n",
            "Epoch 24/90\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0190 - mse: 0.0190\n",
            "Epoch 25/90\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0173 - mse: 0.0173\n",
            "Epoch 26/90\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0193 - mse: 0.0193\n",
            "Epoch 27/90\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0191 - mse: 0.0191\n",
            "Epoch 28/90\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0190 - mse: 0.0190\n",
            "Epoch 29/90\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0165 - mse: 0.0165\n",
            "Epoch 30/90\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0172 - mse: 0.0172\n",
            "Epoch 31/90\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0185 - mse: 0.0185\n",
            "Epoch 32/90\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0145 - mse: 0.0145\n",
            "Epoch 33/90\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0138 - mse: 0.0138\n",
            "Epoch 34/90\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0137 - mse: 0.0137\n",
            "Epoch 35/90\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0150 - mse: 0.0150\n",
            "Epoch 36/90\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0206 - mse: 0.0206\n",
            "Epoch 37/90\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0263 - mse: 0.0263\n",
            "Epoch 38/90\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0184 - mse: 0.0184\n",
            "Epoch 39/90\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0169 - mse: 0.0169\n",
            "Epoch 40/90\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0188 - mse: 0.0188\n",
            "Epoch 41/90\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0176 - mse: 0.0176\n",
            "Epoch 42/90\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0185 - mse: 0.0185\n",
            "Epoch 43/90\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0156 - mse: 0.0156\n",
            "Epoch 44/90\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0156 - mse: 0.0156\n",
            "Epoch 45/90\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0156 - mse: 0.0156\n",
            "Epoch 46/90\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0135 - mse: 0.0135\n",
            "Epoch 47/90\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0124 - mse: 0.0124\n",
            "Epoch 48/90\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0108 - mse: 0.0108\n",
            "Epoch 49/90\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0089 - mse: 0.0089\n",
            "Epoch 50/90\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0091 - mse: 0.0091\n",
            "Epoch 51/90\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0071 - mse: 0.0071\n",
            "Epoch 52/90\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0068 - mse: 0.0068\n",
            "Epoch 53/90\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0057 - mse: 0.0057\n",
            "Epoch 54/90\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0070 - mse: 0.0070\n",
            "Epoch 55/90\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0102 - mse: 0.0102\n",
            "Epoch 56/90\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0192 - mse: 0.0192\n",
            "Epoch 57/90\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0185 - mse: 0.0185\n",
            "Epoch 58/90\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0269 - mse: 0.0269\n",
            "Epoch 59/90\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0167 - mse: 0.0167\n",
            "Epoch 60/90\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0174 - mse: 0.0174\n",
            "Epoch 61/90\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0169 - mse: 0.0169\n",
            "Epoch 62/90\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0170 - mse: 0.0170\n",
            "Epoch 63/90\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0126 - mse: 0.0126\n",
            "Epoch 64/90\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0145 - mse: 0.0145\n",
            "Epoch 65/90\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0152 - mse: 0.0152\n",
            "Epoch 66/90\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0199 - mse: 0.0199\n",
            "Epoch 67/90\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0216 - mse: 0.0216\n",
            "Epoch 68/90\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0258 - mse: 0.0258\n",
            "Epoch 69/90\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0201 - mse: 0.0201\n",
            "Epoch 70/90\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0151 - mse: 0.0151\n",
            "Epoch 71/90\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0212 - mse: 0.0212\n",
            "Epoch 72/90\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0278 - mse: 0.0278\n",
            "Epoch 73/90\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0192 - mse: 0.0192\n",
            "Epoch 74/90\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0147 - mse: 0.0147\n",
            "Epoch 75/90\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0210 - mse: 0.0210\n",
            "Epoch 76/90\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0137 - mse: 0.0137\n",
            "Epoch 77/90\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0103 - mse: 0.0103\n",
            "Epoch 78/90\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.0113 - mse: 0.0113\n",
            "Epoch 79/90\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0133 - mse: 0.0133\n",
            "Epoch 80/90\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.0131 - mse: 0.0131\n",
            "Epoch 81/90\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0118 - mse: 0.0118\n",
            "Epoch 82/90\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0164 - mse: 0.0164\n",
            "Epoch 83/90\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0120 - mse: 0.0120\n",
            "Epoch 84/90\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0136 - mse: 0.0136\n",
            "Epoch 85/90\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.0129 - mse: 0.0129\n",
            "Epoch 86/90\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0157 - mse: 0.0157\n",
            "Epoch 87/90\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0121 - mse: 0.0121\n",
            "Epoch 88/90\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0143 - mse: 0.0143\n",
            "Epoch 89/90\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0161 - mse: 0.0161\n",
            "Epoch 90/90\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0137 - mse: 0.0137\n",
            "[0.15640775859355927, 0.08876199275255203, 0.06382737308740616, 0.05288048833608627, 0.049804456532001495, 0.044658299535512924, 0.0372774675488472, 0.0346023328602314, 0.0324028804898262, 0.030386412516236305, 0.0279813464730978, 0.028654763475060463, 0.028074203059077263, 0.026106227189302444, 0.023370960727334023, 0.023745596408843994, 0.024835053831338882, 0.02493027038872242, 0.021197276189923286, 0.024782661348581314, 0.02207828126847744, 0.022134223952889442, 0.02060425654053688, 0.018959613516926765, 0.01728956028819084, 0.019256610423326492, 0.019143780693411827, 0.018970493227243423, 0.016492178663611412, 0.017170649021863937, 0.018498826771974564, 0.01454918459057808, 0.013821102678775787, 0.013663282617926598, 0.014987317845225334, 0.02064381167292595, 0.026302773505449295, 0.018361827358603477, 0.016880853101611137, 0.018846450373530388, 0.017633790150284767, 0.01847635768353939, 0.015592127107083797, 0.015622138977050781, 0.015582072548568249, 0.013536304235458374, 0.012374665588140488, 0.010773933492600918, 0.008908781222999096, 0.00913638062775135, 0.007125243544578552, 0.006808474659919739, 0.005664650816470385, 0.006951799150556326, 0.01017245277762413, 0.019243018701672554, 0.01848139427602291, 0.02687649428844452, 0.016657259315252304, 0.017419375479221344, 0.016915591433644295, 0.016984878107905388, 0.012610686011612415, 0.014496714808046818, 0.015190147794783115, 0.019911250099539757, 0.02161828614771366, 0.025759322568774223, 0.020062793046236038, 0.015103521756827831, 0.021209629252552986, 0.027836497873067856, 0.019161835312843323, 0.014675552025437355, 0.020993491634726524, 0.013699001632630825, 0.010264001786708832, 0.011253664270043373, 0.013335694558918476, 0.013067763298749924, 0.011848781257867813, 0.016364429146051407, 0.011999708600342274, 0.013584989123046398, 0.012930325232446194, 0.01573552004992962, 0.012141725979745388, 0.01426809560507536, 0.016066499054431915, 0.01371128298342228]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nplt.plot(accu_hist)\\nplt.title('model accuracy')\\nplt.ylabel('accuracy')\\nplt.xlabel('epoch')\\ns = '../working/accuracy_plot_' + str(epochs)\\nplt.savefig(s)\\nplt.show()\\nplt.close()\\n\\nplt.plot(loss_hist)\\nplt.title('model loss')\\nplt.ylabel('loss')\\nplt.xlabel('epoch')\\ns = '../working/loss_plot_' + str(epochs)\\nplt.savefig(s)\\nplt.show()\\nplt.close()\\n\\nmodel.save('../working/2d_4class_axis1.h5')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}