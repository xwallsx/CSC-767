{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "surv-pred-evaluate (1).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shalabh147/Brain-Tumor-Segmentation-and-Survival-Prediction-using-Deep-Neural-Networks/blob/master/surv_pred_evaluate_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "6FmM1Cw1_ivU",
        "colab_type": "code",
        "colab": {},
        "outputId": "a2e113bb-855d-41b0-8d05-ef3d68bbb258"
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "# import keras\n",
        "# from ensorflow import keras\n",
        "from keras import layers\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout,Maximum,Flatten\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose,Conv3D,Conv3DTranspose,UpSampling2D\n",
        "# from tensorflow.keras.layers.convolutional import Conv2D, Conv2DTranspose,Conv3D,Conv3DTranspose,UpSampling2D\n",
        "# from tensorflow.keras.layers.convolutional import Conv2D, Conv2DTranspose,Conv3D,Conv3DTranspose,UpSampling2D\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D,MaxPooling3D,AveragePooling2D\n",
        "from keras.layers.merge import concatenate, add\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from sklearn.utils import class_weight\n",
        "from keras.models import Sequential\n",
        "import nibabel as nib\n",
        "\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "path1 = '../input/vs-brats2018/miccai_brats_2018_data_training/survival_data.csv'\n",
        "#print(os.listdir(path))\n",
        "# Brats18_CBICA_ANP_1\n",
        "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "swpJZ3YZ_iva",
        "colab_type": "code",
        "colab": {},
        "outputId": "90768946-1032-42fb-e88b-78f927de4e47"
      },
      "source": [
        "import csv\n",
        "#import pickle\n",
        "\n",
        "#from joblib import dump\n",
        "\n",
        "age_dict = {}\n",
        "days_dict = {}\n",
        "\n",
        "\n",
        "def dice_coef(y_true, y_pred, epsilon=0.00001):\n",
        "    \"\"\"\n",
        "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
        "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
        "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
        "    \n",
        "    \"\"\"\n",
        "    axis = (0,1,2)\n",
        "    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
        "    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon\n",
        "    return K.mean((dice_numerator)/(dice_denominator))\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1-dice_coef(y_true, y_pred)\n",
        "\n",
        "with open(path1, mode='r') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file,delimiter = ',')\n",
        "    line_count = 0\n",
        "    a = 0\n",
        "    b = 0\n",
        "    max_days = 0\n",
        "    c = 0\n",
        "    for row in csv_reader:\n",
        "        if line_count == 0:\n",
        "            print(f'Column names are {\", \".join(row)}')\n",
        "            line_count += 1\n",
        "        else:\n",
        "            print(row)\n",
        "            key = row[0]\n",
        "            age = row[1]\n",
        "            days = row[2]\n",
        "            age_dict[key] = float(age)\n",
        "            days_dict[key] = int(days)\n",
        "            max_days = max(max_days,int(days))\n",
        "            if int(days) < 250:\n",
        "                a += 1\n",
        "            elif (int(days) >= 250 and int(days) <= 500):\n",
        "                b += 1\n",
        "            else:\n",
        "                c += 1\n",
        "            line_count+=1\n",
        "\n",
        "    print(f'Processed {line_count} lines.')\n",
        "    #age_m = np.zeros((1,1))\n",
        "    print(a,b,c)\n",
        "    print(max_days)\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column names are BraTS18ID, Age, Survival, ResectionStatus\n",
            "['Brats18_TCIA08_167_1', '74.907', '153', 'NA']\n",
            "['Brats18_TCIA08_242_1', '66.479', '147', 'NA']\n",
            "['Brats18_TCIA08_319_1', '64.86', '254', 'NA']\n",
            "['Brats18_TCIA08_469_1', '63.899', '519', 'NA']\n",
            "['Brats18_TCIA08_218_1', '57.345', '346', 'NA']\n",
            "['Brats18_TCIA08_406_1', '78.745', '82', 'NA']\n",
            "['Brats18_TCIA08_280_1', '57.362', '508', 'NA']\n",
            "['Brats18_TCIA08_105_1', '66.627', '77', 'NA']\n",
            "['Brats18_TCIA08_278_1', '50.501', '1458', 'NA']\n",
            "['Brats18_TCIA06_247_1', '76.699', '244', 'NA']\n",
            "['Brats18_TCIA06_372_1', '74.521', '213', 'NA']\n",
            "['Brats18_TCIA06_165_1', '51.756', '5', 'NA']\n",
            "['Brats18_TCIA06_409_1', '69.266', '99', 'NA']\n",
            "['Brats18_TCIA06_184_1', '61.167', '434', 'NA']\n",
            "['Brats18_TCIA05_277_1', '70.367', '232', 'NA']\n",
            "['Brats18_TCIA05_478_1', '59.255', '30', 'NA']\n",
            "['Brats18_TCIA04_437_1', '46.953', '333', 'NA']\n",
            "['Brats18_TCIA04_361_1', '75.973', '476', 'NA']\n",
            "['Brats18_TCIA04_192_1', '75.962', '121', 'NA']\n",
            "['Brats18_TCIA04_479_1', '56.4', '372', 'NA']\n",
            "['Brats18_TCIA04_111_1', '75.263', '626', 'NA']\n",
            "['Brats18_TCIA04_343_1', '52.679', '296', 'NA']\n",
            "['Brats18_TCIA04_149_1', '36.852', '448', 'NA']\n",
            "['Brats18_TCIA03_474_1', '61.408', '635', 'NA']\n",
            "['Brats18_TCIA03_419_1', '70.592', '327', 'NA']\n",
            "['Brats18_TCIA03_199_1', '48.825', '1282', 'NA']\n",
            "['Brats18_TCIA03_133_1', '63.762', '382', 'NA']\n",
            "['Brats18_TCIA03_296_1', '60.427', '22', 'NA']\n",
            "['Brats18_TCIA03_257_1', '69.326', '425', 'NA']\n",
            "['Brats18_TCIA03_498_1', '59.282', '467', 'NA']\n",
            "['Brats18_TCIA03_138_1', '71.874', '82', 'NA']\n",
            "['Brats18_TCIA03_338_1', '76.425', '468', 'NA']\n",
            "['Brats18_TCIA03_265_1', '59.584', '103', 'NA']\n",
            "['Brats18_TCIA03_375_1', '60', '946', 'NA']\n",
            "['Brats18_TCIA03_121_1', '30.408', '747', 'NA']\n",
            "['Brats18_TCIA02_274_1', '54.967', '357', 'NA']\n",
            "['Brats18_TCIA02_473_1', '61.022', '175', 'NA']\n",
            "['Brats18_TCIA02_322_1', '57.362', '621', 'NA']\n",
            "['Brats18_TCIA02_179_1', '46.677', '405', 'NA']\n",
            "['Brats18_TCIA02_368_1', '62.562', '317', 'NA']\n",
            "['Brats18_TCIA02_135_1', '69.364', '828', 'NA']\n",
            "['Brats18_TCIA02_471_1', '76.614', '111', 'NA']\n",
            "['Brats18_TCIA02_394_1', '64.247', '616', 'NA']\n",
            "['Brats18_TCIA02_300_1', '64.378', '127', 'NA']\n",
            "['Brats18_TCIA02_151_1', '47.973', '1731', 'NA']\n",
            "['Brats18_TCIA02_118_1', '47.321', '104', 'NA']\n",
            "['Brats18_TCIA02_226_1', '73.578', '329', 'NA']\n",
            "['Brats18_TCIA02_455_1', '54.844', '424', 'NA']\n",
            "['Brats18_TCIA02_283_1', '74.836', '262', 'NA']\n",
            "['Brats18_TCIA02_430_1', '53.866', '71', 'NA']\n",
            "['Brats18_TCIA02_321_1', '81.211', '67', 'NA']\n",
            "['Brats18_TCIA02_314_1', '40.353', '362', 'NA']\n",
            "['Brats18_TCIA02_290_1', '43.112', '737', 'NA']\n",
            "['Brats18_TCIA02_377_1', '63.762', '812', 'NA']\n",
            "['Brats18_TCIA02_198_1', '54.279', '394', 'NA']\n",
            "['Brats18_TCIA02_331_1', '84.844', '187', 'NA']\n",
            "['Brats18_TCIA02_491_1', '81.112', '82', 'NA']\n",
            "['Brats18_TCIA01_150_1', '51.115', '1489', 'NA']\n",
            "['Brats18_TCIA01_335_1', '54.474', '355', 'NA']\n",
            "['Brats18_TCIA01_411_1', '42.904', '822', 'NA']\n",
            "['Brats18_TCIA01_203_1', '45.926', '268', 'NA']\n",
            "['Brats18_TCIA01_231_1', '63.805', '1561', 'NA']\n",
            "['Brats18_TCIA01_390_1', '63.575', '634', 'NA']\n",
            "['Brats18_TCIA01_235_1', '57.973', '804', 'NA']\n",
            "['Brats18_TCIA01_499_1', '50.082', '600', 'NA']\n",
            "['Brats18_TCIA01_412_1', '68.759', '291', 'NA']\n",
            "['Brats18_TCIA01_448_1', '44.449', '199', 'NA']\n",
            "['Brats18_TCIA01_401_1', '78.792', '448', 'NA']\n",
            "['Brats18_TCIA01_147_1', '61.416', '209', 'NA']\n",
            "['Brats18_TCIA01_378_1', '74.145', '110', 'NA']\n",
            "['Brats18_TCIA01_201_1', '60.729', '430', 'NA']\n",
            "['Brats18_TCIA01_429_1', '54.986', '86', 'NA']\n",
            "['Brats18_TCIA01_186_1', '33.888', '370', 'NA']\n",
            "['Brats18_TCIA01_460_1', '18.975', '630', 'NA']\n",
            "['Brats18_TCIA01_190_1', '61.526', '322', 'NA']\n",
            "['Brats18_TCIA01_425_1', '56.208', '558', 'NA']\n",
            "['Brats18_2013_11_1', '29.12', '150', 'GTR']\n",
            "['Brats18_2013_27_1', '68.02', '120', 'GTR']\n",
            "['Brats18_CBICA_BHM_1', '62.03', '436', 'STR']\n",
            "['Brats18_CBICA_BHB_1', '55.595', '510', 'GTR']\n",
            "['Brats18_CBICA_AZH_1', '54.915', '401', 'GTR']\n",
            "['Brats18_CBICA_AZD_1', '46.258', '448', 'GTR']\n",
            "['Brats18_CBICA_AYW_1', '49.874', '734', 'NA']\n",
            "['Brats18_CBICA_AYU_1', '63.781', '58', 'GTR']\n",
            "['Brats18_CBICA_AYI_1', '65.921', '387', 'GTR']\n",
            "['Brats18_CBICA_AYA_1', '74.836', '50', 'GTR']\n",
            "['Brats18_CBICA_AXW_1', '79.211', '191', 'GTR']\n",
            "['Brats18_CBICA_AXQ_1', '66.282', '114', 'GTR']\n",
            "['Brats18_CBICA_AXO_1', '56.301', '394', 'NA']\n",
            "['Brats18_CBICA_AXN_1', '85.762', '345', 'GTR']\n",
            "['Brats18_CBICA_AXM_1', '66.934', '438', 'STR']\n",
            "['Brats18_CBICA_AXL_1', '74.63', '168', 'GTR']\n",
            "['Brats18_CBICA_AXJ_1', '27.811', '1767', 'GTR']\n",
            "['Brats18_CBICA_AWI_1', '46.551', '375', 'GTR']\n",
            "['Brats18_CBICA_AWH_1', '52.764', '139', 'GTR']\n",
            "['Brats18_CBICA_AWG_1', '55.532', '180', 'GTR']\n",
            "['Brats18_CBICA_AVV_1', '72.293', '387', 'GTR']\n",
            "['Brats18_CBICA_AVJ_1', '45.244', '614', 'GTR']\n",
            "['Brats18_CBICA_AVG_1', '63.359', '579', 'GTR']\n",
            "['Brats18_CBICA_AUR_1', '70.252', '12', 'GTR']\n",
            "['Brats18_CBICA_AUQ_1', '60.816', '1337', 'NA']\n",
            "['Brats18_CBICA_AUN_1', '68.504', '376', 'GTR']\n",
            "['Brats18_CBICA_ATX_1', '36.784', '1592', 'GTR']\n",
            "['Brats18_CBICA_ATV_1', '62.159', '453', 'GTR']\n",
            "['Brats18_CBICA_ATP_1', '51.589', '385', 'GTR']\n",
            "['Brats18_CBICA_ATF_1', '68.726', '152', 'GTR']\n",
            "['Brats18_CBICA_ATD_1', '69.178', '355', 'GTR']\n",
            "['Brats18_CBICA_ATB_1', '71.126', '208', 'GTR']\n",
            "['Brats18_CBICA_ASY_1', '66.51', '610', 'STR']\n",
            "['Brats18_CBICA_ASW_1', '68.359', '239', 'GTR']\n",
            "['Brats18_CBICA_ASV_1', '54.751', '597', 'GTR']\n",
            "['Brats18_CBICA_ASU_1', '81.285', '85', 'STR']\n",
            "['Brats18_CBICA_ASO_1', '52.348', '265', 'STR']\n",
            "['Brats18_CBICA_ASN_1', '39.488', '407', 'STR']\n",
            "['Brats18_CBICA_ASK_1', '77.337', '522', 'GTR']\n",
            "['Brats18_CBICA_ASH_1', '46.57', '660', 'GTR']\n",
            "['Brats18_CBICA_ASG_1', '57.71', '208', 'STR']\n",
            "['Brats18_CBICA_ASE_1', '46.814', '318', 'STR']\n",
            "['Brats18_CBICA_ASA_1', '63.764', '210', 'STR']\n",
            "['Brats18_CBICA_ARZ_1', '54.825', '871', 'STR']\n",
            "['Brats18_CBICA_ARW_1', '44.416', '495', 'STR']\n",
            "['Brats18_CBICA_ARF_1', '75.312', '726', 'GTR']\n",
            "['Brats18_CBICA_AQZ_1', '63.345', '286', 'STR']\n",
            "['Brats18_CBICA_AQY_1', '57.718', '229', 'STR']\n",
            "['Brats18_CBICA_AQV_1', '53.362', '84', 'GTR']\n",
            "['Brats18_CBICA_AQU_1', '72.879', '30', 'STR']\n",
            "['Brats18_CBICA_AQT_1', '75.978', '172', 'GTR']\n",
            "['Brats18_CBICA_AQR_1', '71.37', '89', 'GTR']\n",
            "['Brats18_CBICA_AQQ_1', '69.992', '33', 'STR']\n",
            "['Brats18_CBICA_AQP_1', '46.452', '1283', 'GTR']\n",
            "['Brats18_CBICA_AQO_1', '67.86', '473', 'GTR']\n",
            "['Brats18_CBICA_AQN_1', '63.192', '488', 'STR']\n",
            "['Brats18_CBICA_AQJ_1', '66.074', '170', 'STR']\n",
            "['Brats18_CBICA_AQG_1', '53.605', '466', 'STR']\n",
            "['Brats18_CBICA_AQD_1', '73.036', '32', 'STR']\n",
            "['Brats18_CBICA_AQA_1', '76.367', '106', 'GTR']\n",
            "['Brats18_CBICA_APZ_1', '60.063', '336', 'STR']\n",
            "['Brats18_CBICA_APY_1', '45.548', '203', 'STR']\n",
            "['Brats18_CBICA_APR_1', '62.704', '23', 'STR']\n",
            "['Brats18_CBICA_AOZ_1', '46.666', '331', 'GTR']\n",
            "['Brats18_CBICA_AOP_1', '67.833', '332', 'GTR']\n",
            "['Brats18_CBICA_AOO_1', '44.162', '350', 'GTR']\n",
            "['Brats18_CBICA_AOH_1', '56.921', '576', 'GTR']\n",
            "['Brats18_CBICA_AOD_1', '60.581', '55', 'NA']\n",
            "['Brats18_CBICA_ANZ_1', '68.049', '287', 'GTR']\n",
            "['Brats18_CBICA_ANP_1', '61.605', '486', 'GTR']\n",
            "['Brats18_CBICA_ANI_1', '58.258', '439', 'GTR']\n",
            "['Brats18_CBICA_ANG_1', '55.759', '368', 'GTR']\n",
            "['Brats18_CBICA_AMH_1', '62.614', '169', 'GTR']\n",
            "['Brats18_CBICA_AME_1', '51.734', '359', 'GTR']\n",
            "['Brats18_CBICA_ALX_1', '59.693', '698', 'GTR']\n",
            "['Brats18_CBICA_ALU_1', '65.899', '495', 'GTR']\n",
            "['Brats18_CBICA_ALN_1', '60.942', '421', 'STR']\n",
            "['Brats18_CBICA_ABY_1', '48.367', '515', 'GTR']\n",
            "['Brats18_CBICA_ABO_1', '56.419', '1155', 'GTR']\n",
            "['Brats18_CBICA_ABN_1', '68.285', '1278', 'STR']\n",
            "['Brats18_CBICA_ABM_1', '69.912', '503', 'GTR']\n",
            "['Brats18_CBICA_ABE_1', '67.126', '269', 'GTR']\n",
            "['Brats18_CBICA_ABB_1', '68.493', '465', 'GTR']\n",
            "['Brats18_CBICA_AAP_1', '39.068', '788', 'GTR']\n",
            "['Brats18_CBICA_AAL_1', '54.301', '464', 'GTR']\n",
            "['Brats18_CBICA_AAG_1', '52.263', '616', 'GTR']\n",
            "['Brats18_CBICA_AAB_1', '60.463', '289', 'GTR']\n",
            "Processed 164 lines.\n",
            "55 64 44\n",
            "1767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "x1zuUuXE_ive",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "surv_model = load_model('../input/heheregression/surv_predreg.h5')\n",
        "seg_model = load_model('../input/surv-pred-models/2d_4class_axis3.h5' , custom_objects = {'dice_coef_loss' :  dice_coef_loss , 'dice_coef' : dice_coef})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "P7I1StLN_ivh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '../input/vs-brats2018/miccai_brats_2018_data_training/HGG'\n",
        "all_images = os.listdir(path)\n",
        "#print(len(all_images))\n",
        "all_images.sort()\n",
        "\n",
        "def standardize(image):\n",
        "\n",
        "  standardized_image = np.zeros(image.shape)\n",
        "\n",
        "  #\n",
        " \n",
        "      # iterate over the `z` dimension\n",
        "  for z in range(image.shape[2]):\n",
        "      # get a slice of the image\n",
        "      # at channel c and z-th dimension `z`\n",
        "      image_slice = image[:,:,z]\n",
        "\n",
        "      # subtract the mean from image_slice\n",
        "      centered = image_slice - np.mean(image_slice)\n",
        "     \n",
        "      # divide by the standard deviation (only if it is different from zero)\n",
        "      if(np.std(centered)!=0):\n",
        "          centered = centered/np.std(centered)\n",
        "\n",
        "      # update  the slice of standardized image\n",
        "      # with the scaled centered and scaled image\n",
        "      standardized_image[:, :, z] = centered\n",
        "\n",
        "  ### END CODE HERE ###\n",
        "\n",
        "  return standardized_image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "H2slVvwn_ivk",
        "colab_type": "code",
        "colab": {},
        "outputId": "4a28f289-9e08-472b-a061-625894560e10"
      },
      "source": [
        "#loss_hist = []\n",
        "#accu_hist = []\n",
        "#epoch_wise_loss = []\n",
        "#epoch_wise_accu = []\n",
        "#for epochs in range(45):\n",
        "epoch_loss = 0\n",
        "epoch_accu = 0\n",
        "input_to_model = np.zeros((29,240,240,5))\n",
        "age = np.zeros((29,1))\n",
        "ground_truth = np.zeros((29,1))\n",
        "cnt = 0\n",
        "for image_num in range(170,210):\n",
        "    #print(epochs)\n",
        "    #print(\"image_num \",image_num)\n",
        "    #print(\"cnt\" ,cnt)\n",
        "    data = np.zeros((240,240,155,4))\n",
        "    image_data2=np.zeros((240,240,155))\n",
        "\n",
        "    # data preprocessing starts here\n",
        "\n",
        "    x = all_images[image_num]\n",
        "    \n",
        "    if x in days_dict:\n",
        "        #print(cnt)\n",
        "        #print(x)\n",
        "        folder_path = path + '/' + x;\n",
        "        modalities = os.listdir(folder_path)\n",
        "        modalities.sort()\n",
        "        #data = []\n",
        "        w = 0\n",
        "        for j in range(len(modalities)):\n",
        "          #print(modalities[j])\n",
        "\n",
        "          image_path = folder_path + '/' + modalities[j]\n",
        "          if not(image_path.find('seg.nii') == -1):\n",
        "            img = nib.load(image_path);\n",
        "            image_data2 = img.get_data()\n",
        "            image_data2 = np.asarray(image_data2)\n",
        "            #print(\"Entered ground truth\")\n",
        "          else:\n",
        "            img = nib.load(image_path);\n",
        "            image_data = img.get_data()\n",
        "            image_data = np.asarray(image_data)\n",
        "            image_data = standardize(image_data)\n",
        "            data[:,:,:,w] = image_data\n",
        "            #print(\"Entered modality\")\n",
        "            w = w+1\n",
        "\n",
        "        #print(data.shape)\n",
        "        #print(image_data2.shape)\n",
        "        image_data2[image_data2 == 4] = 3\n",
        "\n",
        "        input_to_model[cnt,:,:,:4] = data[:,:,75,:]\n",
        "        #input_to_model[cnt,:,:,4] = image_data2[:,:,75]\n",
        "        #age = np.zeros((1,1))\n",
        "        age[cnt,0] = float(age_dict[x])\n",
        "        days = int(days_dict[x])\n",
        "        \n",
        "\n",
        "        #ground_truth = np.zeros((1,3))\n",
        "        #print(age[cnt,0])\n",
        "        '''\n",
        "        if int(days) < 300:\n",
        "            ground_truth[cnt,0] = 1\n",
        "        elif (int(days) >= 300 and int(days) <= 450):\n",
        "            ground_truth[cnt,1] = 1\n",
        "        else:\n",
        "            ground_truth[cnt,2] = 1 \n",
        "        '''\n",
        "        ground_truth[cnt,0] = int(days)/max_days\n",
        "        #print(ground_truth[cnt])\n",
        "        cnt += 1\n",
        "        \n",
        "\n",
        "    #y_to = keras.utils.to_categorical(y_to,num_classes=4)\n",
        "to_segment = input_to_model[:,:,:,:4]\n",
        "after_segment = seg_model.predict(x = to_segment)\n",
        "print(after_segment.shape)\n",
        "after_segment = np.argmax(after_segment, axis = -1)\n",
        "input_to_model[:,:,:,4] = after_segment\n",
        "#print(ground_truth.shape)\n",
        "#print(age.shape)\n",
        "#print(input_to_model.shape)\n",
        "scores = surv_model.evaluate(x = [input_to_model,age], y = ground_truth)\n",
        "pred = surv_model.predict(x=[input_to_model,age])\n",
        "print(ground_truth*max_days)\n",
        "print(pred*max_days)\n",
        "#pred = np.argmax(pred,axis = -1)\n",
        "#ground_truth = np.argmax(ground_truth,axis = -1)\n",
        "#print(pred == ground_truth)\n",
        "#print(history.history['loss'])\n",
        "#epoch_loss += history.history['loss'][0]\n",
        "#epoch_accu += history.history['accuracy'][0]\n",
        "\n",
        "#loss_hist.append(history.history['loss'])\n",
        "#accu_hist.append(history.history['accuracy'])\n",
        "\n",
        "#model.save('../working/surv_pred3.h5')\n",
        "#epoch_loss = epoch_loss/180\n",
        "#epoch_accu = epoch_accu/180\n",
        "\n",
        "#epoch_wise_loss.append(epoch_loss)\n",
        "#epoch_wise_accu.append(epoch_accu)\n",
        "''' \n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model_loss vs epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epochs')\n",
        "s = '../working/epochwise_loss'\n",
        "plt.savefig(s)\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Model_Accuracy vs epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "s = '../working/epochwise_accuracy'\n",
        "plt.savefig(s)\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "\n",
        "plt.plot(accu_hist)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "s = '../working/accuracy_plot_' + str(epochs)\n",
        "plt.savefig(s)\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "plt.plot(loss_hist)\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "s = '../working/loss_plot_' + str(epochs)\n",
        "plt.savefig(s)\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "model.save('../working/2d_4class_axis1.h5')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:42: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
            "\n",
            "* deprecated from version: 3.0\n",
            "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
            "\n",
            "* deprecated from version: 3.0\n",
            "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(29, 240, 240, 4)\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.2107 - mean_squared_error: 0.2107\n",
            "[[  22.]\n",
            " [ 468.]\n",
            " [ 946.]\n",
            " [ 327.]\n",
            " [ 635.]\n",
            " [ 467.]\n",
            " [ 626.]\n",
            " [ 448.]\n",
            " [ 121.]\n",
            " [ 296.]\n",
            " [ 476.]\n",
            " [ 333.]\n",
            " [ 372.]\n",
            " [ 232.]\n",
            " [  30.]\n",
            " [   5.]\n",
            " [ 434.]\n",
            " [ 244.]\n",
            " [ 213.]\n",
            " [  99.]\n",
            " [  77.]\n",
            " [ 153.]\n",
            " [ 346.]\n",
            " [ 147.]\n",
            " [1458.]\n",
            " [ 508.]\n",
            " [ 254.]\n",
            " [  82.]\n",
            " [ 519.]]\n",
            "[[ 813.6175 ]\n",
            " [ 250.73135]\n",
            " [ 958.6666 ]\n",
            " [ 972.3248 ]\n",
            " [1279.6447 ]\n",
            " [1312.3201 ]\n",
            " [1098.0134 ]\n",
            " [1498.8267 ]\n",
            " [ 772.1209 ]\n",
            " [1388.0165 ]\n",
            " [1032.0972 ]\n",
            " [1105.5706 ]\n",
            " [1393.6545 ]\n",
            " [1303.1383 ]\n",
            " [1195.2557 ]\n",
            " [1296.0067 ]\n",
            " [1485.108  ]\n",
            " [ 379.31024]\n",
            " [1175.849  ]\n",
            " [ 463.3608 ]\n",
            " [ 896.01764]\n",
            " [ 840.3019 ]\n",
            " [1275.8517 ]\n",
            " [ 980.8081 ]\n",
            " [1321.864  ]\n",
            " [1606.7034 ]\n",
            " [ 706.48157]\n",
            " [1166.2017 ]\n",
            " [1070.7634 ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" \\nplt.plot(history.history['loss'])\\nplt.title('Model_loss vs epochs')\\nplt.ylabel('Loss')\\nplt.xlabel('epochs')\\ns = '../working/epochwise_loss'\\nplt.savefig(s)\\nplt.show()\\nplt.close()\\n\\nplt.plot(history.history['accuracy'])\\nplt.title('Model_Accuracy vs epochs')\\nplt.ylabel('Accuracy')\\nplt.xlabel('epochs')\\ns = '../working/epochwise_accuracy'\\nplt.savefig(s)\\nplt.show()\\nplt.close()\\n\\n\\nplt.plot(accu_hist)\\nplt.title('model accuracy')\\nplt.ylabel('accuracy')\\nplt.xlabel('epoch')\\ns = '../working/accuracy_plot_' + str(epochs)\\nplt.savefig(s)\\nplt.show()\\nplt.close()\\n\\nplt.plot(loss_hist)\\nplt.title('model loss')\\nplt.ylabel('loss')\\nplt.xlabel('epoch')\\ns = '../working/loss_plot_' + str(epochs)\\nplt.savefig(s)\\nplt.show()\\nplt.close()\\n\\nmodel.save('../working/2d_4class_axis1.h5')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    }
  ]
}